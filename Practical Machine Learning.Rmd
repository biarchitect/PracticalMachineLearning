---
title: "Practical Machine Learning Project"
author: "Todd H. Robinson"
date: "Friday, July 25, 2014"
output: html_document
---

##Executive Summary
The goal of this project is to predict the manner in which a group of people did certain exercises.
We will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants as they exercise.
Random Forest function was used to build a prediction model.
The data was downloaded from here;
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv.

This data will be cleansed and partitioned into training and validation sets in order to build an efficient and accurate prediction model.
The model will then be tested against a test dataset downloaded from here;

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

##Conclusion

The model produced was efficient in that it took a little over 3 minutes to build.
The training set was built from 50% of the training data.
It contains 56 variables of interest and was 100% accurate on both the validation and test datasets.
The Out of sample error was very small. THe model built resulted in an accuracy of 0.9925 within a confidence interval of (0.9905, 0.9941) with a p-value of 0. 
The model was 100% accurate againest the 20 test cases.

##Methodology
###Step 1 - Download the data
```{r echo=TRUE}
filename<-"./Data/pml-training.csv"
data<-read.csv(filename,header=T,stringsAsFactors=F)
```
###Step 2 - Data cleansing
Remove all variables that do not contain a high percentage of data. Actually all variables that contain at least one NA observation.
``` {r echo=TRUE}
cleandata<-function(temp){
  
  #The first four variables are row counts, timestamps, who did the exercise and the window.
  #Remove them as they add nothing to the predicive goal of the model.
  temp<-temp[,-1:-7]
  #Make any empty cells NA
  temp[temp==""]<-NA
  #Make all bad Math cells NA
  temp[temp=="#DIV/0!"]<-NA
  
  #Get rid of all variables that are ALL NA
  temp<-temp[,!apply(temp,2,function(x) all(is.na(x)))]
  #Remove all variables with less than NApct of real data.
  NApct<-1
  m<-dim(temp)[1];x<-1;y<-dim(temp)[2]
  while (x < y){if (sum(!is.na(temp[,x]))/m < NApct) {temp[,x]<-NULL;y<-dim(temp)[2]} else{ x<-x+1}}
  
  temp<-apply(temp[,c(-53)],2,as.numeric)
  temp<-as.data.frame(temp)
  return(temp)
}
temp<-cleandata(data)
temp$classe<-as.factor(data[,160])

```

###Step 3 - Partition the cleansed dataset
``` {r echo=TRUE}
library(caret)
set.seed(658)
#Partition 50/50
part<-0.50
training<-createDataPartition(temp$classe, p = .50)[[1]]

train<-temp[training,]
vdate<-temp[-training,]

```
###Step 4  - Build the model

``` {r echo=TRUE}
library(randomForest)
modelFit<-randomForest(classe~.,data=train)
#Validate 
confusionMatrix(vdate$classe,predict(modelFit,newdata=vdate[,-53]))
```


### Generate out of sample error

###Step 5 - Test model
``` {r echo=TRUE}
filename<-"./Data/pml-testing.csv"
#Get Data
dataT<-read.csv(filename,stringsAsFactors=F)
#Clean Data
test<-cleandata(dataT)
#Add Outcome Variable to Test set
test$problem_id<-as.factor(dataT[,160])
#Create a prdiction
x<-predict(modelFit,newdata=test)
#Test those predictions againest the 20 predictions submitted to Course as correct.
good<-as.factor(c("B","A","B","A","A","E","D","B","A","A","B","C","B","A","E","E","A","B","B","B"))
confusionMatrix(good,x)
```
###Citations
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013. 


